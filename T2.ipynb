{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificador de tênis (Nike vs Adidas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregamento de dados dos datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasetLoader(data_dir, batch_size):\n",
    "    # antes do data agumentation -> transform = transforms.Compose([transforms.Resize((256, 256)), transforms.ToTensor()])\n",
    "    transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomRotation(15),\n",
    "    torchvision.transforms.RandomResizedCrop(size=(224, 224)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "])\n",
    "    \n",
    "\n",
    "    train_dir = os.path.join(data_dir, \"Train\")\n",
    "    test_dir = os.path.join(data_dir, \"Test\")\n",
    "    val_dir = os.path.join(data_dir, \"Validation\")\n",
    "\n",
    "    train_data = ImageFolder(root=train_dir, transform=transform)\n",
    "    test_data = ImageFolder(root=test_dir, transform=transform)\n",
    "    val_data = ImageFolder(root=val_dir, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "    val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"Dataset\"\n",
    "train_loader, test_loader, val_loader = datasetLoader(data_dir, batch_size=12)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_classes = len(train_loader.dataset.classes)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de amostras de treinamento: 459\n",
      "Número de amostras de teste: 50\n",
      "Número de amostras de validação: 55\n",
      "Classes no conjunto de treinamento:\n",
      "['adidas', 'nike']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Número de amostras de treinamento: {len(train_loader.dataset)}\")\n",
    "print(f\"Número de amostras de teste: {len(test_loader.dataset)}\")\n",
    "print(f\"Número de amostras de validação: {len(val_loader.dataset)}\")\n",
    "print(\"Classes no conjunto de treinamento:\")\n",
    "print(train_loader.dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\guilh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "resnet = torchvision.models.resnet50(weights = True)\n",
    "resnet.fc = nn.Linear(2048, num_classes)\n",
    "resnet = resnet.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métodos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(model, loader):\n",
    "    model.eval()\n",
    "    confusion_matrix = np.zeros((2,2))\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _,predicted = torch.max(outputs, 1)\n",
    "            for i in range(labels.size(0)):\n",
    "                confusion_matrix[labels[i].item()][predicted[i].item()] += 1\n",
    "    ax = sns.heatmap(confusion_matrix, annot=True, cmap='Blues', fmt='g', xticklabels=['Adidas', 'Nike'], yticklabels=['Adidas', 'Nike'])\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('Label')\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acurácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, loader):\n",
    "    model.eval()\n",
    "    corrected = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _,predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            corrected += (predicted == labels).sum().item()\n",
    "    return corrected * 100 // total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(model, loader):\n",
    "    model.eval()\n",
    "    total_positives = len(loader.dataset.targets)\n",
    "    correct_positives = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _,predicted = torch.max(outputs, 1)\n",
    "\n",
    "            correct_positives += (predicted == labels).sum().item()\n",
    "\n",
    "    if total_positives == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return correct_positives / total_positives * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(model, loader):\n",
    "    model.eval()\n",
    "    total_positive_predictions = 0\n",
    "    correct_positive_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            total_positive_predictions += (predicted == 1).sum().item()\n",
    "            correct_positive_predictions += ((predicted == 1) & (labels == 1)).sum().item()\n",
    "            total_predictions += labels.size(0)\n",
    "\n",
    "    if total_positive_predictions == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        precision = correct_positive_predictions / total_positive_predictions\n",
    "        return precision * 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, loader, criterion):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs,labels)\n",
    "            val_loss +=loss\n",
    "    return val_loss/len(loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "l1_lambda e l2 lambda são os pesos/intensidade que a regularização aplicará no modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_regularization(model, l1_lambda, device):\n",
    "    l1_reg = torch.tensor(0., device=device)\n",
    "    for param in model.parameters():\n",
    "        # Calculando a norma L1 dos parâmetros e somando-as\n",
    "        l1_reg += torch.norm(param, 1)\n",
    "    # Multiplicando pela lambda para obter o termo de regularização L1\n",
    "    return l1_lambda * l1_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_regularization(model, l2_lambda, device):\n",
    "    l2_reg = torch.tensor(0., device=device)\n",
    "    for param in model.parameters():\n",
    "        # Calculando a norma L2 dos parâmetros e somando suas raízes quadradas\n",
    "        l2_reg += torch.norm(param, 2) ** 2\n",
    "    # Multiplicando pela lambda e raiz quadrada para obter o termo de regularização L2\n",
    "    return l2_lambda * torch.sqrt(l2_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, trainloader, testloader, optimizer, criterion, epochs, l1_lambda, l2_lambda):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0\n",
    "        for data in tqdm(trainloader):\n",
    "            images, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            l1_reg = l1_regularization(model, l1_lambda, device)\n",
    "            loss += l1_reg\n",
    "            l2_reg = l2_regularization(model, l2_lambda, device)\n",
    "            loss += l2_reg\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        val_loss = validation(model, testloader, criterion)\n",
    "        print(f'Epoch: {epoch+1} | Loss: {running_loss/len(trainloader)} | Val Loss: {val_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registro de evoluções nos modelos\n",
    "- 1º modelo era treinado com apenas 3 épocas e com learning rate de 0,001. **Acurácia de 70%**.\n",
    "- 2º modelo subimos o número de épocas para 30 (número baseado nos modelos analisados da referência 1) e ajustamos o learning rate para 0,0001. **Acurácia de 88%**.\n",
    "- 3º modelo inserimos regularização L1 e L2 com peso da regularização de 0,01. **Acurácia caiu para 76%**\n",
    "- 4º modelo ajustamos os parâmetros de pesos da regularização L1 e L2 para de 0,0001. **Acurácia de 90%**\n",
    "\n",
    "Referências:  \n",
    "1 - https://www.kaggle.com/datasets/ifeanyinneji/nike-adidas-shoes-for-image-classification-dataset/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resnet.parameters(), lr=0.0001)\n",
    "l1_lambda = 0.0001\n",
    "l2_lambda = 0.0001\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 38/39 [00:13<00:00,  2.90it/s]c:\\Users\\guilh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "100%|██████████| 39/39 [00:13<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Loss: 0.4223478805178251 | Val Loss: 1.1621726751327515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:13<00:00,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Loss: 0.23908608072461227 | Val Loss: 0.47943755984306335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:12<00:00,  3.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Loss: 0.2915422426871 | Val Loss: 0.49639907479286194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:13<00:00,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | Loss: 0.258840677782129 | Val Loss: 0.6434466242790222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:13<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | Loss: 0.17472739823353597 | Val Loss: 0.6676902770996094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:13<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 | Loss: 0.20236977187391275 | Val Loss: 0.5977053046226501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:13<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 | Loss: 0.10710250581495273 | Val Loss: 0.7168561220169067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:13<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 | Loss: 0.10718619665847375 | Val Loss: 0.20801575481891632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:13<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 | Loss: 0.11434427245209615 | Val Loss: 0.22941628098487854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:13<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Loss: 0.09415258221232738 | Val Loss: 0.7204878330230713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:13<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Loss: 0.1946908842640905 | Val Loss: 0.7877001166343689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:13<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | Loss: 0.2022521044485844 | Val Loss: 0.453432559967041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:13<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | Loss: 0.2272447146093234 | Val Loss: 0.42323365807533264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:13<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | Loss: 0.2046438694382325 | Val Loss: 0.3329326808452606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:13<00:00,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Loss: 0.16533137494936967 | Val Loss: 0.39255276322364807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:13<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | Loss: 0.1255855974383079 | Val Loss: 0.35297438502311707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:13<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 | Loss: 0.14517910641212112 | Val Loss: 0.6208309531211853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:13<00:00,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 | Loss: 0.11037510471084179 | Val Loss: 0.28500694036483765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:13<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 | Loss: 0.08781892236453505 | Val Loss: 0.5891388058662415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:13<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 | Loss: 0.1063416169072764 | Val Loss: 0.7161462306976318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:13<00:00,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21 | Loss: 0.09387757046482502 | Val Loss: 0.8161396980285645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:13<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22 | Loss: 0.08137847555096811 | Val Loss: 0.2832145392894745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:13<00:00,  2.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23 | Loss: 0.09431732757291637 | Val Loss: 0.413581520318985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:13<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24 | Loss: 0.1425129251482968 | Val Loss: 1.544830560684204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:13<00:00,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25 | Loss: 0.109887941650903 | Val Loss: 0.324146568775177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:13<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26 | Loss: 0.10952608055697802 | Val Loss: 0.820733368396759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:13<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27 | Loss: 0.06836759000539015 | Val Loss: 0.3979169726371765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:13<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28 | Loss: 0.0943659566438351 | Val Loss: 0.8450342416763306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:13<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29 | Loss: 0.08411467742198744 | Val Loss: 0.7758395075798035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:14<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30 | Loss: 0.11727730939403558 | Val Loss: 0.6261100172996521\n"
     ]
    }
   ],
   "source": [
    "train(resnet, train_loader, test_loader, optimizer, criterion, epochs=epochs, l1_lambda=l1_lambda, l2_lambda=l2_lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métricas de avaliação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acurácia do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A rede atinge: 92% de acurácia\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f'A rede atinge: {accuracy(resnet, test_loader)}% de acurácia')\n",
    "conf_mat = confusion_matrix(resnet, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A rede atinge: 84.0% de recall\n",
      "A rede atinge: 89.29% de precisão\n"
     ]
    }
   ],
   "source": [
    "print(f'A rede atinge: {round(recall(resnet, test_loader),2)}% de recall')\n",
    "print(f'A rede atinge: {round(precision(resnet, test_loader),2)}% de precisão')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usabilidade de webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "img_counter = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow('Webcam', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    elif cv2.waitKey(1) & 0xFF == ord('e'):\n",
    "            img_name = \"WebcamImages/print_{}.png\".format(img_counter)\n",
    "            cv2.imwrite(img_name, frame)\n",
    "            print(\"{} written!\".format(img_name))\n",
    "            img_counter += 1\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, image):\n",
    "    prediction = model(torch.unsqueeze(image, 0).to(device))\n",
    "    result = torch.argmax(prediction)\n",
    "    return 'Adidas' if result == 0 else 'Nike'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predição das classes da webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "for filename in os.listdir('WebcamImages'):\n",
    "    if filename.endswith(\".png\"):\n",
    "        x = Image.open('WebcamImages/' + filename).convert('RGB')\n",
    "        x = transforms.Compose([transforms.Resize((256, 256)), transforms.ToTensor()])(x)\n",
    "        print(f'Image: {filename} | Resnet Prediction: {predict(resnet, x)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
