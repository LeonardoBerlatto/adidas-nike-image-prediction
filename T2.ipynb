{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificador de tênis (Nike vs Adidas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregamento de dados dos datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separa em treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def datasetLoader(data_dir, batch_size):\n",
    "    transform = transforms.Compose([transforms.Resize((256, 256)), transforms.ToTensor()])\n",
    "    train_dir = os.path.join(data_dir, \"Training\")\n",
    "    train_data = ImageFolder(root=train_dir, transform=transform)\n",
    "\n",
    "    train_indices, test_indices = train_test_split(\n",
    "        range(len(train_data)), test_size=0.33, random_state=42\n",
    "    )\n",
    "\n",
    "    train_subset = Subset(train_data, train_indices)\n",
    "    test_subset = Subset(train_data, test_indices)\n",
    "\n",
    "    training_loader = DataLoader(\n",
    "        train_subset, batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_subset, batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "\n",
    "    return training_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch size e device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"Dataset\"\n",
    "train_loader, test_loader = datasetLoader(data_dir, batch_size=12)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Número total de amostras: {len(test_loader.dataset)+len(train_loader.dataset)}\")\n",
    "print(f\"Número de amostras de treinamento: {len(train_loader.dataset)}\")\n",
    "print(f\"Número de amostras de teste: {len(test_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " O dropout será ativado entre a camada convolucional final da ResNet50 e a camada linear que produzirá a saída final do modelo. Durante o treinamento, o dropout aleatoriamente \"desliga\" neurônios, reduzindo a dependência entre eles, o que ajuda a prevenir o overfitting. Dropout ajudou muito para diminuir a valor da função custo de validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = torchvision.models.resnet50(weights = True)\n",
    "resnet.fc = torch.nn.Sequential(\n",
    "    torch.nn.Dropout(0.6),  # Adicionando dropout com probabilidade 0.5\n",
    "    torch.nn.Linear(2048, 2)\n",
    ")\n",
    "resnet = resnet.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métodos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(model, loader):\n",
    "    model.eval()\n",
    "    confusion_matrix = np.zeros((2,2))\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _,predicted = torch.max(outputs, 1)\n",
    "            for i in range(labels.size(0)):\n",
    "                confusion_matrix[labels[i].item()][predicted[i].item()] += 1\n",
    "    ax = sns.heatmap(confusion_matrix, annot=True, cmap='Blues', fmt='g', xticklabels=['Adidas', 'Nike'], yticklabels=['Adidas', 'Nike'])\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('Label')\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acurácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, loader):\n",
    "    model.eval()\n",
    "    corrected = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _,predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            corrected += (predicted == labels).sum().item()\n",
    "    return corrected * 100 // total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def calculate_f1_score(model, loader):\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            predicted_labels.extend(predicted.cpu().numpy())\n",
    "    return f1_score(true_labels, predicted_labels, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC AUC métrica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "def calculate_roc_auc_score(model, loader, n_classes):\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    predicted_probs = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            predicted_probs.extend(probs.cpu().numpy())\n",
    "    true_labels = label_binarize(true_labels, classes=[i for i in range(n_classes)])\n",
    "    return roc_auc_score(true_labels, predicted_probs, multi_class='ovr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, loader, criterion):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs,labels)\n",
    "            val_loss += loss.item()\n",
    "    return val_loss/len(loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "l1_lambda e l2 lambda são os pesos/intensidade que a regularização aplicará no modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_regularization(model, l1_lambda, device):\n",
    "    l1_reg = torch.tensor(0., device=device)\n",
    "    for param in model.parameters():\n",
    "        # Calculando a norma L1 dos parâmetros e somando-as\n",
    "        l1_reg += torch.norm(param, 1)\n",
    "    # Multiplicando pela lambda para obter o termo de regularização L1\n",
    "    return l1_lambda * l1_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_regularization(model, l2_lambda, device):\n",
    "    l2_reg = torch.tensor(0., device=device)\n",
    "    for param in model.parameters():\n",
    "        # Calculando a norma L2 dos parâmetros e somando suas raízes quadradas\n",
    "        l2_reg += torch.norm(param, 2) ** 2\n",
    "    # Multiplicando pela lambda e raiz quadrada para obter o termo de regularização L2\n",
    "    return l2_lambda * torch.sqrt(l2_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "def train(model, trainloader, testloader, optimizer, criterion, epochs, l1_lambda, l2_lambda, device, lr_patience, early_stop_patience):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_without_improvement = 0\n",
    "\n",
    "    lr_scheduler = ReduceLROnPlateau(optimizer, patience=lr_patience, verbose=True)  # Se a perda de validação não melhorar por x épocas, reduz a taxa de aprendizado em 0,1\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0\n",
    "        for data in tqdm(trainloader):\n",
    "            images, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            l1_reg = l1_regularization(model, l1_lambda, device)    ##  L1 e L2 regularization  ##\n",
    "            l2_reg = l2_regularization(model, l2_lambda, device)    ##  L1 e L2 regularization  ##     \n",
    "            loss += l1_reg + l2_reg                                 ##  L1 e L2 regularization  ##\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        val_loss = validation(model, testloader, criterion)\n",
    "        lr_scheduler.step(val_loss)                                 ##  Learning Rate Scheduler  ##\n",
    "        train_losses.append(running_loss/len(trainloader))\n",
    "        val_losses.append(val_loss)\n",
    "        print(f'Epoch: {epoch+1} | Train Loss: {train_losses[-1]} | Val Loss: {val_loss}')\n",
    "\n",
    "        if val_loss < best_val_loss:                                ##  Early Stopping  ##\n",
    "            best_val_loss = val_loss                                \n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            if epochs_without_improvement >= early_stop_patience:\n",
    "                print(f'Parada antecipada na época {epoch+1}, pois a loss na validação não apresentou melhora.')\n",
    "                break\n",
    "        \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_losses, label='Training Loss', marker='o')\n",
    "    plt.plot(val_losses, label='Validation Loss', marker='x')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss over Epochs')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registro de evoluções nos modelos\n",
    "- 1º modelo era treinado com apenas 3 épocas e com learning rate de 0,001. **Acurácia de 70%**.\n",
    "- 2º modelo subimos o número de épocas para 30 (número baseado nos modelos analisados da referência 1) e ajustamos o learning rate para 0,0001. **Acurácia de 88%**.\n",
    "- 3º modelo inserimos regularização L1 e L2 com peso da regularização de 0,01. **Acurácia caiu para 76%**\n",
    "- 4º modelo ajustamos os parâmetros de pesos da regularização L1 e L2 para de 0,00001. **Acurácia de 90%**\n",
    "\n",
    "Referências:  \n",
    "1 - https://www.kaggle.com/datasets/ifeanyinneji/nike-adidas-shoes-for-image-classification-dataset/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resnet.parameters(), lr=0.0001)\n",
    "l1_lambda = 0.001\n",
    "l2_lambda = 0.01\n",
    "epochs = 60 \n",
    "lr_patience = 3\n",
    "early_stop_patience = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(resnet, train_loader, test_loader, optimizer, criterion, epochs=epochs, l1_lambda=l1_lambda, l2_lambda=l2_lambda, device=device, lr_patience=lr_patience, early_stop_patience=early_stop_patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métricas de avaliação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'A rede atinge: {accuracy(resnet, test_loader)}% de acurácia')\n",
    "print(f'A rede atinge: {round(calculate_f1_score(resnet, test_loader)*100,2)}% de f1 Score')\n",
    "print(f'A rede atinge: {round(calculate_roc_auc_score(resnet, test_loader, 50)*100,2)}% de ROC AUC Score')\n",
    "conf_mat = confusion_matrix(resnet, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'A rede atinge: {accuracy(resnet, train_loader)}% de acurácia')\n",
    "print(f'A rede atinge: {round(calculate_f1_score(resnet, train_loader)*100,2)}% de recall')\n",
    "print(f'A rede atinge: {round(calculate_roc_auc_score(resnet, train_loader, 50)*100,2)}% de ROC AUC Score')\n",
    "conf_mat = confusion_matrix(resnet, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnet.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usabilidade de webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "img_counter = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow('Webcam', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    elif cv2.waitKey(1) & 0xFF == ord('e'):\n",
    "            img_name = \"WebcamImages/print_{}.png\".format(img_counter)\n",
    "            cv2.imwrite(img_name, frame)\n",
    "            print(\"{} written!\".format(img_name))\n",
    "            img_counter += 1\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, image):\n",
    "    prediction = model(torch.unsqueeze(image, 0).to(device))\n",
    "    result = torch.argmax(prediction)\n",
    "    return 'Adidas' if result == 0 else 'Nike'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predição das classes da webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = torch.load('model.pth')\n",
    "resnet.load_state_dict(cnn)\n",
    "from PIL import Image\n",
    "for filename in os.listdir('WebcamImages'):\n",
    "    if filename.endswith(\".png\"):\n",
    "        x = Image.open('WebcamImages/' + filename).convert('RGB')\n",
    "        x = transforms.Compose([transforms.Resize((256, 256)), transforms.ToTensor()])(x)\n",
    "        print(f'Image: {filename} | Resnet Prediction: {predict(resnet, x)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
