{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificador de tênis (Nike vs Adidas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregamento de dados dos datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasetLoader(data_dir, batch_size):\n",
    "    transform = transforms.Compose([transforms.Resize((256, 256)), transforms.ToTensor()])\n",
    "\n",
    "    train_dir = os.path.join(data_dir, \"Train\")\n",
    "    test_dir = os.path.join(data_dir, \"Test\")\n",
    "    val_dir = os.path.join(data_dir, \"Validation\")\n",
    "\n",
    "    train_data = ImageFolder(root=train_dir, transform=transform)\n",
    "    test_data = ImageFolder(root=test_dir, transform=transform)\n",
    "    val_data = ImageFolder(root=val_dir, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "    val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"Dataset\"\n",
    "train_loader, test_loader, val_loader = datasetLoader(data_dir, batch_size=12)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_classes = len(train_loader.dataset.classes)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Número de amostras de treinamento: {len(train_loader.dataset)}\")\n",
    "print(f\"Número de amostras de teste: {len(test_loader.dataset)}\")\n",
    "print(f\"Número de amostras de validação: {len(val_loader.dataset)}\")\n",
    "print(\"Classes no conjunto de treinamento:\")\n",
    "print(train_loader.dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = torchvision.models.resnet50(weights = True)\n",
    "resnet.fc = nn.Linear(2048, num_classes)\n",
    "resnet = resnet.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métodos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(model, loader):\n",
    "    model.eval()\n",
    "    confusion_matrix = np.zeros((2,2))\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _,predicted = torch.max(outputs, 1)\n",
    "            for i in range(labels.size(0)):\n",
    "                confusion_matrix[labels[i].item()][predicted[i].item()] += 1\n",
    "    ax = sns.heatmap(confusion_matrix, annot=True, cmap='Blues', fmt='g', xticklabels=['Adidas', 'Nike'], yticklabels=['Adidas', 'Nike'])\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('Label')\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acurácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, loader):\n",
    "    model.eval()\n",
    "    corrected = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _,predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            corrected += (predicted == labels).sum().item()\n",
    "    return corrected * 100 // total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, loader, criterion):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs,labels)\n",
    "            val_loss +=loss\n",
    "    return val_loss/len(loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_regularization(model, l1_lambda, device):\n",
    "    l1_reg = torch.tensor(0., device=device)\n",
    "    for param in model.parameters():\n",
    "        # Calculando a norma L1 dos parâmetros e somando-as\n",
    "        l1_reg += torch.norm(param, 1)\n",
    "    # Multiplicando pela lambda para obter o termo de regularização L1\n",
    "    return l1_lambda * l1_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_regularization(model, l2_lambda, device):\n",
    "    l2_reg = torch.tensor(0., device=device)\n",
    "    for param in model.parameters():\n",
    "        # Calculando a norma L2 dos parâmetros e somando suas raízes quadradas\n",
    "        l2_reg += torch.norm(param, 2) ** 2\n",
    "    # Multiplicando pela lambda e raiz quadrada para obter o termo de regularização L2\n",
    "    return l2_lambda * torch.sqrt(l2_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, trainloader, testloader, optimizer, criterion, epochs, l1_lambda, l2_lambda):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0\n",
    "        for data in tqdm(trainloader):\n",
    "            images, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            l1_reg = l1_regularization(model, l1_lambda, device)\n",
    "            loss += l1_reg\n",
    "            l2_reg = l2_regularization(model, l2_lambda, device)\n",
    "            loss += l2_reg\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        val_loss = validation(model, testloader, criterion)\n",
    "        print(f'Epoch: {epoch+1} | Loss: {running_loss/len(trainloader)} | Val Loss: {val_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registro de evoluções nos modelos\n",
    "- 1º modelo era treinado com apenas 3 épocas e com learning rate de 0,001. **Acurácia de 70%**.\n",
    "- 2º modelo subimos o número de épocas para 30 (número baseado nos modelos analisados da referência 1) e ajustamos o learning rate para 0,0001. **Acurácia de 88%**.\n",
    "- 3º modelo inserimos regularização L1 e L2 com peso da regularização de 0,01. **Acurácia caiu para 76%**\n",
    "- 4º modelo ajustamos os parâmetros de pesos da regularização L1 e L2 para de 0,0001. **Acurácia de 94%**\n",
    "\n",
    "Referências:  \n",
    "1 - https://www.kaggle.com/datasets/ifeanyinneji/nike-adidas-shoes-for-image-classification-dataset/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resnet.parameters(), lr=0.0001)\n",
    "l1_lambda = 0.0001\n",
    "l2_lambda = 0.0001\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(resnet, train_loader, test_loader, optimizer, criterion, epochs=epochs, l1_lambda=l1_lambda, l2_lambda=l2_lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acurácia do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'A rede atinge: {accuracy(resnet, test_loader)}% de acurácia')\n",
    "conf_mat = confusion_matrix(resnet, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usabilidade de webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "img_counter = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow('Webcam', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    elif cv2.waitKey(1) & 0xFF == ord('e'):\n",
    "            img_name = \"WebcamImages/print_{}.png\".format(img_counter)\n",
    "            cv2.imwrite(img_name, frame)\n",
    "            print(\"{} written!\".format(img_name))\n",
    "            img_counter += 1\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, image):\n",
    "    prediction = model(torch.unsqueeze(image, 0).to(device))\n",
    "    result = torch.argmax(prediction)\n",
    "    return 'Adidas' if result == 0 else 'Nike'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predição das classes da webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "for filename in os.listdir('WebcamImages'):\n",
    "    if filename.endswith(\".png\"):\n",
    "        x = Image.open('WebcamImages/' + filename).convert('RGB')\n",
    "        x = transforms.Compose([transforms.Resize((256, 256)), transforms.ToTensor()])(x)\n",
    "        print(f'Image: {filename} | Resnet Prediction: {predict(resnet, x)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
